{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project_pop.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victoria2012/TeamProject/blob/master/project_pop_modify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuPJQQBu5CtW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9dd7fc2-4576-41f6-9db4-a43c3fbc7637"
      },
      "source": [
        "!pip install -U finance-datareader\n",
        "import FinanceDataReader as fdr\n",
        "df_krx = fdr.StockListing('KRX')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting finance-datareader\n",
            "  Downloading finance_datareader-0.9.31-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from finance-datareader) (4.2.6)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.7/dist-packages (from finance-datareader) (1.1.5)\n",
            "Collecting requests-file\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from finance-datareader) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from finance-datareader) (4.62.0)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->finance-datareader) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->finance-datareader) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->finance-datareader) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.19.2->finance-datareader) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance-datareader) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance-datareader) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance-datareader) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance-datareader) (2021.5.30)\n",
            "Installing collected packages: requests-file, finance-datareader\n",
            "Successfully installed finance-datareader-0.9.31 requests-file-1.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ref5ZY7ab72",
        "outputId": "e58449e4-5082-4470-e2b5-be99fea678e5"
      },
      "source": [
        "import sqlite3\n",
        "conn = sqlite3.connect('./db.sqlite3')\n",
        "c = conn.cursor()\n",
        "c.execute(\"CREATE TABLE IF NOT EXISTS article (id INTEGER PRIMARY KEY AUTOINCREMENT, date TEXT, time TEXT, title TEXT, press TEXT , stock TEXT, posi_nega TEXT, link TEXT)\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sqlite3.Cursor at 0x7f595713d500>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxEvZodO3NTd"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# https://jsikim1.tistory.com/143\n",
        "from datetime import datetime , timedelta\n",
        "from dateutil.relativedelta import relativedelta \n",
        "\n",
        "now = datetime.now()\n",
        "gap = now - relativedelta(years=2)\n",
        "# gap = now - timedelta(days=1)\n",
        "\n",
        "now = str(now)[0:10]\n",
        "gap = str(gap)[0:10]\n",
        "\n",
        "dt_index = pd.date_range(start=gap, end=now)\n",
        "dt_list = dt_index.strftime(\"%Y%m%d\").tolist()\n",
        "\n",
        "for j in dt_list:\n",
        "\n",
        "  date_cnt_uri = 'https://finance.naver.com/news/news_list.nhn?mode=LSS3D&section_id=101&section_id2=258&section_id3=402&date='+j+'&page=100'\n",
        "  date_cnt_target = date_cnt_uri\n",
        "  date_cnt_req  = requests.get(date_cnt_target)\n",
        "  date_cnt_soup = BeautifulSoup(date_cnt_req.content,'html.parser')\n",
        "  date_cnt_page = int(date_cnt_soup.select('td.on > a ')[0].get_text())\n",
        "  \n",
        "  uri = 'https://finance.naver.com/news/news_list.nhn?mode=LSS3D&section_id=101&section_id2=258&section_id3=402&date='+j+'&page='\n",
        "\n",
        "  df_krx_list = df_krx['Name'].tolist()\n",
        "\n",
        "  for page in range(1,date_cnt_page+1):    \n",
        "\n",
        "    target = uri+str(page)\n",
        "    req  = requests.get(target)\n",
        "    soup = BeautifulSoup(req.content,'html.parser')\n",
        "    datas = soup.select('#contentarea_left > ul.realtimeNewsList')\n",
        "\n",
        "    for content in datas:\n",
        "      \n",
        "      titles = content.select(' li > dl > dd.articleSubject')\n",
        "      article_date =  content.select('li > dl > dd.articleSummary > span.wdate ')\n",
        "      article_press =  content.select('li > dl > dd.articleSummary > span.press ') \n",
        "      article_link = content.select('li > dl > dd.articleSubject > a ') \n",
        "\n",
        "      article_sum = list()\n",
        "      \n",
        "      for i in range(0,len(titles)-1):\n",
        "        article_data = list()\n",
        "        \n",
        "        data_date = article_date[i].get_text(\" \",strip=True)[0:10]\n",
        "        data_time = article_date[i].get_text(\" \",strip=True)[11:17]\n",
        "        data_press = article_press[i].get_text(\" \",strip=True)\n",
        "        data_title = titles[i].get_text(\" \",strip=True)\n",
        "        data_link = \"https://finance.naver.com\"+article_link[i][\"href\"]\n",
        "        data_stock = 'stock'\n",
        "\n",
        "        for i in range(0,len(data_title.split())):\n",
        "          if data_title.split()[i] in df_krx_list:\n",
        "            data_stock = data_title.split()[i]\n",
        "\n",
        "        c.execute(\"INSERT INTO article( date , time , press , title, stock , posi_nega ,link ) VALUES(?,?,?,?,?,?,?)\",( data_date,data_time,data_press,data_title,data_stock,'posi_nega',data_link))\n",
        "        conn.commit()\n",
        "\n",
        "# c.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYeFjABVjNdS"
      },
      "source": [
        "# conn = sqlite3.connect('/content/db.stock')\n",
        "\n",
        "# c_title = conn.cursor()\n",
        "# c_id = conn.cursor()\n",
        "# c_update = conn.cursor()\n",
        "\n",
        "# c_title.execute(\"SELECT title FROM article \")\n",
        "# c_id.execute(\"SELECT * FROM article \")\n",
        "\n",
        "# sql_title = c_title.fetchall()\n",
        "# sql_id = c_id.fetchall()\n",
        "\n",
        "# title_list = [list[0] for list in sql_title ]\n",
        "# id_list = [list[0] for list in sql_id ]\n",
        "\n",
        "# df_krx_list = df_krx['Name'].tolist()\n",
        "\n",
        "# for k in range(0,len(title_list)):\n",
        "#   for l in range(0,int(len(title_list[k].split()))):\n",
        "#     keyword = title_list[k].split()[l]\n",
        "#     if keyword in df_krx_list:\n",
        "#       sql_update = 'update article set stock = \"' + keyword +'\" where id = ' + str(sql_id[k][0])\n",
        "#       c_update.execute(sql_update)\n",
        "#       conn.commit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od1PQUw0Zat4"
      },
      "source": [
        "conn = sqlite3.connect('/content/db.sqlite3')\n",
        "c_select = conn.cursor()\n",
        "final = c_select.execute(\"SELECT * FROM article where stock != 'stock' order by date desc , time desc\")\n",
        "df = pd.DataFrame(final)\n",
        "df.columns= ['id', 'date' , 'time' , 'title', 'press' ,'stock' , 'posi_nega','link']\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9snic7R0yTm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}